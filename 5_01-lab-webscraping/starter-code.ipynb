{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a soup object from the home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Set the url of the webpage to scrape\n",
    "url = \"https://pages.git.generalassemb.ly/rldaggie/for-scraping/\"\n",
    "# Generate a response\n",
    "response = requests.get(url)\n",
    "# Print response, if response = 200, all is good\n",
    "print(response.status_code)\n",
    "# Pull the HTML string out of requests and convert it to a Python string.\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup Object\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the home page soup for every restaurant\n",
    "\n",
    "Note: Your best bet is to create a list of dictionaries, one for each restaurant. Each dictionary contains the restaurant's name and path from the `href`. The result of your scrape should look something like this:\n",
    "\n",
    "```python\n",
    "restaurants = [\n",
    "    {'name': 'A&W Restaurants', 'href': 'restaurants/1.html'}, \n",
    "    {'name': \"Applebee's\", 'href': 'restaurants/2.html'},\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define result list\n",
    "results_list = []\n",
    "# Gather table data from main page\n",
    "main_pg_td = soup.find_all(\"td\")\n",
    "# Gather title of restaurant and link\n",
    "for element in main_pg_td:\n",
    "    # start a dictionary to store this item's data\n",
    "    result = {}\n",
    "    # get the title and full link/url\n",
    "    a_href = element.find('a')\n",
    "    if a_href:\n",
    "        result['restaurant'] = a_href.text   # element text\n",
    "        result['link'] = a_href['href'] # href link\n",
    "        results_list.append(result)\n",
    "# results_list is the data with resturant name and link to it\n",
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'restaurant': 'A&W Restaurants', 'link': 'restaurants/1.html'},\n",
       " {'restaurant': \"Applebee's\", 'link': 'restaurants/2.html'},\n",
       " {'restaurant': \"Arby's\", 'link': 'restaurants/3.html'},\n",
       " {'restaurant': 'Atlanta Bread Company', 'link': 'restaurants/4.html'},\n",
       " {'restaurant': \"Bojangle's Famous Chicken 'n Biscuits\",\n",
       "  'link': 'restaurants/5.html'},\n",
       " {'restaurant': 'Buffalo Wild Wings', 'link': 'restaurants/6.html'},\n",
       " {'restaurant': 'Burger King', 'link': 'restaurants/7.html'},\n",
       " {'restaurant': \"Captain D's\", 'link': 'restaurants/8.html'},\n",
       " {'restaurant': \"Carl's Jr.\", 'link': 'restaurants/9.html'},\n",
       " {'restaurant': \"Charley's Grilled Subs\", 'link': 'restaurants/10.html'},\n",
       " {'restaurant': 'Chick-fil-A', 'link': 'restaurants/11.html'},\n",
       " {'restaurant': \"Chili's\", 'link': 'restaurants/12.html'},\n",
       " {'restaurant': 'Chipotle Mexican Grill', 'link': 'restaurants/13.html'},\n",
       " {'restaurant': \"Church's\", 'link': 'restaurants/14.html'},\n",
       " {'restaurant': 'Corner Bakery Cafe', 'link': 'restaurants/15.html'},\n",
       " {'restaurant': 'Dairy Queen', 'link': 'restaurants/16.html'},\n",
       " {'restaurant': \"Denny's\", 'link': 'restaurants/17.html'},\n",
       " {'restaurant': 'El Pollo Loco', 'link': 'restaurants/18.html'},\n",
       " {'restaurant': 'FATZ', 'link': 'restaurants/19.html'},\n",
       " {'restaurant': \"Fazoli's\", 'link': 'restaurants/20.html'},\n",
       " {'restaurant': 'Five Guys Burgers and Fries', 'link': 'restaurants/21.html'},\n",
       " {'restaurant': 'Golden Chick', 'link': 'restaurants/22.html'},\n",
       " {'restaurant': \"Hardee's\", 'link': 'restaurants/23.html'},\n",
       " {'restaurant': 'IHOP', 'link': 'restaurants/24.html'},\n",
       " {'restaurant': 'In-N-Out Burger', 'link': 'restaurants/25.html'},\n",
       " {'restaurant': 'Jack in the Box', 'link': 'restaurants/26.html'},\n",
       " {'restaurant': 'Jimmy Johns', 'link': 'restaurants/27.html'},\n",
       " {'restaurant': \"Joe's Crab Shack\", 'link': 'restaurants/28.html'},\n",
       " {'restaurant': 'KFC', 'link': 'restaurants/29.html'},\n",
       " {'restaurant': \"McDonald's\", 'link': 'restaurants/30.html'},\n",
       " {'restaurant': \"O'Charley's\", 'link': 'restaurants/31.html'},\n",
       " {'restaurant': 'Olive Garden', 'link': 'restaurants/32.html'},\n",
       " {'restaurant': 'Outback Steakhouse', 'link': 'restaurants/33.html'},\n",
       " {'restaurant': 'Panda Express', 'link': 'restaurants/34.html'},\n",
       " {'restaurant': 'Panera Bread', 'link': 'restaurants/35.html'},\n",
       " {'restaurant': \"Popeye's\", 'link': 'restaurants/36.html'},\n",
       " {'restaurant': 'Quiznos', 'link': 'restaurants/37.html'},\n",
       " {'restaurant': 'Red Robin Gourmet Burgers', 'link': 'restaurants/38.html'},\n",
       " {'restaurant': \"Romano's Macaroni Grill\", 'link': 'restaurants/39.html'},\n",
       " {'restaurant': 'Ruby Tuesday', 'link': 'restaurants/40.html'},\n",
       " {'restaurant': 'Subway', 'link': 'restaurants/41.html'},\n",
       " {'restaurant': 'Taco Bell', 'link': 'restaurants/42.html'},\n",
       " {'restaurant': 'Taco Bueno', 'link': 'restaurants/43.html'},\n",
       " {'restaurant': \"Wendy's\", 'link': 'restaurants/44.html'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Using the `href`, scrape each restaurant's page and create a single list of food dictionaries.\n",
    "\n",
    "Your list of foods should look something like this:\n",
    "```python\n",
    "foods = [\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Note**: Remove extra white space from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_heading(pg_soup):\n",
    "    '''Find the table headings of a page\n",
    "    Arg:\n",
    "        pg_soup: soup object of that page\n",
    "    Return:\n",
    "        res_pg_th_lst: result of page table head in a list\n",
    "    '''\n",
    "    res_pg_th_lst = []\n",
    "    # Gather table heading data from main page\n",
    "    res_pg_th = pg_soup.find_all(\"th\")\n",
    "    for th in res_pg_th:\n",
    "        res_pg_th_lst.append(th.text.lower())\n",
    "    return res_pg_th_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_table_content(pg_soup, res_pg_th_lst, pg_name, food_lst):\n",
    "    '''Find the contents in the table and update food_lst\n",
    "    Args:\n",
    "        pg_soup: soup object of that page\n",
    "        res_pg_th_lst: result of page table head in a list\n",
    "        pg_name: name of the page\n",
    "        food_lst: existing data list\n",
    "    Return:\n",
    "        food_lst: updated food_lst\n",
    "    '''\n",
    "    # Find the table\n",
    "    res_pg_table = pg_soup.find(\"table\", class_=\"table\")\n",
    "    # Find the rows in table body\n",
    "    for row in res_pg_table.tbody.find_all('tr'):    \n",
    "        # Find all data entry for each row\n",
    "        column = row.find_all('td')\n",
    "        if (column != []):\n",
    "            # dict comprehension to tie th and td\n",
    "            col_dict = {th: td.text.strip() for th, td in zip(res_pg_th_lst, column)}\n",
    "            # insert name of restaurant\n",
    "            col_dict['restaurant']=pg_name\n",
    "            food_lst.append(col_dict)\n",
    "    return food_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_lst = []\n",
    "for res in results_list:\n",
    "    pg_link = res['link']\n",
    "    pg_name = res['restaurant']\n",
    "    # Create soup obj for each page\n",
    "    pg_response = requests.get(url+pg_link)\n",
    "    pg_html = pg_response.text\n",
    "    pg_soup = BeautifulSoup(pg_html, 'lxml')\n",
    "    # for each page, find headings\n",
    "    res_pg_th_lst = find_heading(pg_soup)\n",
    "    # for each page, update food_lst\n",
    "    food_lst = find_table_content(pg_soup,res_pg_th_lst,pg_name,food_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5131"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(food_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a pandas DataFrame from your list of foods\n",
    "\n",
    "**Note**: Your DataFrame should have 5,131 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(food_lst,index=list(range(0,5131)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>calories</th>\n",
       "      <th>fat</th>\n",
       "      <th>carbs</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original Bacon Double Cheeseburger</td>\n",
       "      <td>Burgers</td>\n",
       "      <td>760</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>A&amp;W Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coney (Chili) Dog</td>\n",
       "      <td>Entrees</td>\n",
       "      <td>340</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>A&amp;W Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chili Fries</td>\n",
       "      <td>French Fries</td>\n",
       "      <td>370</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>A&amp;W Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Strawberry Milkshake (small)</td>\n",
       "      <td>Shakes</td>\n",
       "      <td>670</td>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>A&amp;W Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A&amp;WÂ® Root Beer Freeze (large)</td>\n",
       "      <td>Shakes</td>\n",
       "      <td>820</td>\n",
       "      <td>18</td>\n",
       "      <td>150</td>\n",
       "      <td>A&amp;W Restaurants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name      category calories fat carbs  \\\n",
       "0  Original Bacon Double Cheeseburger       Burgers      760  45    45   \n",
       "1                   Coney (Chili) Dog       Entrees      340  20    26   \n",
       "2                         Chili Fries  French Fries      370  15    49   \n",
       "3        Strawberry Milkshake (small)        Shakes      670  29    90   \n",
       "4      A&WÂ® Root Beer Freeze (large)        Shakes      820  18   150   \n",
       "\n",
       "        restaurant  \n",
       "0  A&W Restaurants  \n",
       "1  A&W Restaurants  \n",
       "2  A&W Restaurants  \n",
       "3  A&W Restaurants  \n",
       "4  A&W Restaurants  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Export to csv\n",
    "\n",
    "**Note:** Don't export the index column from your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './scrapped_result.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(save_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi-sg]",
   "language": "python",
   "name": "conda-env-dsi-sg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
